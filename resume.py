import streamlit as st
import pandas as pd
import pdfplumber
import docx
import json
import requests
import io
import time
from datetime import datetime

# ==========================================
# 0. é…ç½®ä¸å¸¸é‡
# ==========================================

st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ç­›é€‰ç³»ç»Ÿ V3.2", layout="wide", page_icon="ğŸ“")

TARGET_CITY = "æ·±åœ³"

# å®šä¹‰ JSON æå–çš„ Schema
# å…³é”®ä¿®æ”¹ï¼šå¢åŠ äº† school_tier å­—æ®µï¼Œè®© AI è‡ªå·±åˆ¤æ–­
JSON_SCHEMA = """
{
    "basic_info": {
        "name": "å§“å",
        "gender": "æ€§åˆ«(ç”·/å¥³)",
        "age": "å¹´é¾„(æ•°å­—)",
        "phone": "ç”µè¯",
        "subject": "åº”è˜å­¦ç§‘",
        "marital_status": "å©šè‚²çŠ¶å†µ(å·²å©šå·²è‚²/å·²å©šæœªè‚²/æœªå©š/æœªæåŠ)",
        "residence": "ç°å±…ä½åŸå¸‚",
        "partner_location": "é…å¶/ä¼´ä¾£å·¥ä½œåœ°åŸå¸‚",
        "parents_background": "çˆ¶æ¯èŒä¸šæˆ–å•ä½èƒŒæ™¯æ‘˜è¦"
    },
    "education": {
        "high_school": "é«˜ä¸­æ ¡å",
        "high_school_tier": "é«˜ä¸­æ¡£æ¬¡(é‡ç‚¹é«˜ä¸­/å¿ä¸­/æ™®é€š/æœªçŸ¥)",
        "bachelor_school": "æœ¬ç§‘æ ¡å",
        "bachelor_tier": "æœ¬ç§‘å­¦æ ¡å±‚æ¬¡(å¿…é¡»ä»ä»¥ä¸‹é€‰é¡¹é€‰æ‹©å…¶ä¸€: C9/985/211/ä¸€æœ¬/äºŒæœ¬/æµ·å¤–åæ ¡/æµ·å¤–æ™®é€š)",
        "bachelor_major": "æœ¬ç§‘ä¸“ä¸š",
        "master_school": "ç ”ç©¶ç”Ÿæ ¡å",
        "master_tier": "ç ”ç©¶ç”Ÿå­¦æ ¡å±‚æ¬¡(å¿…é¡»ä»ä»¥ä¸‹é€‰é¡¹é€‰æ‹©å…¶ä¸€: C9/985/211/ä¸€æœ¬/äºŒæœ¬/æµ·å¤–åæ ¡/æµ·å¤–æ™®é€š)",
        "master_major": "ç ”ç©¶ç”Ÿä¸“ä¸š",
        "study_abroad_years": "æµ·å¤–ç•™å­¦æ—¶é•¿(å¹´ï¼Œæ•°å­—)",
        "exchange_experience": "æ˜¯å¦æœ‰äº¤æ¢ç»å†(æ˜¯/å¦)"
    },
    "work_experience": {
        "current_company": "ç°ä»»èŒå•ä½",
        "school_tier": "ç°å•ä½æ¡£æ¬¡(å¸‚é‡ç‚¹/çŸ¥åæ°‘åŠ/æ™®é€š/æœºæ„/å…¶ä»–)",
        "non_teaching_gap": "éæ•™è¡Œä¸šç©ºçª—æœŸ(å¹´ï¼Œæ•°å­—ï¼Œæ— åˆ™ä¸º0)",
        "gap_explanation_valid": "ç©ºçª—æœŸè§£é‡Šæ˜¯å¦åˆç†(æ˜¯/å¦/æ— ç©ºçª—)",
        "overseas_work_years": "æµ·å¤–å·¥ä½œæ—¶é•¿(å¹´ï¼Œæ•°å­—)",
        "management_role": "æ›¾ä»»ç®¡ç†å²—(ä¸­å±‚/å¹´çº§ç»„é•¿/æ•™ç ”ç»„é•¿/æ— )",
        "head_teacher_years": "ç­ä¸»ä»»å¹´é™(æ•°å­—)",
        "teaching_years": "æ•™é¾„(é¢„ä¼°æ•°å­—)"
    },
    "achievements": {
        "honor_titles": ["è£èª‰ç§°å·åˆ—è¡¨(å¦‚å­¦ç§‘å¸¦å¤´äºº, éª¨å¹²æ•™å¸ˆ, ä¼˜é’)"],
        "teaching_competition": ["èµ›è¯¾è·å¥–åˆ—è¡¨(å¦‚ä¼˜è´¨è¯¾ä¸€ç­‰å¥–)"],
        "academic_results": ["è¯¾é¢˜æˆ–è®ºæ–‡æˆæœæ‘˜è¦"]
    },
    "ai_assessment": {
        "summary": "ä¸€å¥è¯äº®ç‚¹æ‘˜è¦(ä¾‹å¦‚ï¼šC9ç¡•å£«ï¼Œæœ‰å¥¥èµ›è¾…å¯¼ç»éªŒï¼Œç”·æ€§)",
        "teaching_philosophy": "æ•™å­¦ç†å¿µæ€»ç»“",
        "resume_quality_score": "ç®€å†ç²¾ç»†åº¦è¯„åˆ†(1-5åˆ†)",
        "career_trajectory": "èŒä¸šè·¯å¾„(ä¸Šå‡å‹/å¹³ç¨³å‹/ä¸‹è¡Œå‹)",
        "potential_score": "AIæ½œè´¨è¯„åˆ†(1-5åˆ†)",
        "risk_warning": "é£é™©æç¤º(å¦‚ï¼šæ¯•ä¸šåæœ‰3å¹´éæ•™å­¦å·¥ä½œç»å†ï¼Œæˆ–æ— )"
    }
}
"""

# ==========================================
# 1. é˜¶æ®µä¸€ï¼šæ–‡ä»¶é¢„å¤„ç† (File Ingestion)
# ==========================================

def extract_text_from_pdf(file_bytes):
    """è§£æ PDF æ–‡ä»¶"""
    text = ""
    try:
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        return f"Error reading PDF: {str(e)}"
    return text

def extract_text_from_docx(file_bytes):
    """è§£æ Word æ–‡ä»¶"""
    text = ""
    try:
        doc = docx.Document(io.BytesIO(file_bytes))
        for para in doc.paragraphs:
            text += para.text + "\n"
    except Exception as e:
        return f"Error reading DOCX: {str(e)}"
    return text

def parse_files(uploaded_files):
    """æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    parsed_data = []
    for file in uploaded_files:
        file_name = file.name
        content = file.read()
        text = ""
        
        if file_name.lower().endswith('.pdf'):
            text = extract_text_from_pdf(content)
        elif file_name.lower().endswith(('.docx', '.doc')):
            text = extract_text_from_docx(content)
        else:
            text = "Unsupported file format."
            
        parsed_data.append({"filename": file_name, "content": text})
    return parsed_data

# ==========================================
# 2. é˜¶æ®µäºŒï¼šAI æ™ºèƒ½æå– (AI Extraction)
# ==========================================

def call_deepseek_api(text, api_key):
    """è°ƒç”¨ SiliconFlow API (DeepSeek-V3.2) è¿›è¡Œç®€å†è§£æ"""
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HRæ‹›è˜ä¸“å®¶åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç®€å†æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºæ ‡å‡†çš„JSONæ ¼å¼ã€‚
    
    å…³é”®æŒ‡ä»¤ï¼š
    1. **å­¦æ ¡å±‚æ¬¡è¯†åˆ«**ï¼šè¯·åˆ©ç”¨ä½ çš„çŸ¥è¯†åº“ï¼Œè‡ªåŠ¨è¯†åˆ«æœ¬ç§‘å’Œç ”ç©¶ç”Ÿå­¦æ ¡çš„å±‚æ¬¡ï¼ˆC9ã€985ã€211ã€é‡ç‚¹å¸ˆèŒƒã€æµ·å¤–åæ ¡ç­‰ï¼‰ï¼Œå¹¶å¡«å……åˆ° 'bachelor_tier' å’Œ 'master_tier' å­—æ®µä¸­ã€‚
    2. **é«˜ä¸­è¯†åˆ«**ï¼šè¯†åˆ«é«˜ä¸­æ˜¯å¦ä¸ºè‘—åçš„é‡ç‚¹é«˜ä¸­ï¼ˆå¦‚å„çœå¸‚ç¬¬ä¸€ä¸­å­¦ã€å¸ˆå¤§é™„ä¸­ç­‰ï¼‰ã€‚
    3. **è¾“å‡ºæ ¼å¼**ï¼šå¿…é¡»æ˜¯åˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«Markdownæ ‡è®°ã€‚
    4. **æ½œè´¨è¯„åˆ†**ï¼šæ ¹æ®ç®€å†çš„è‡ªæˆ‘è¯„ä»·ã€æ’ç‰ˆè´¨é‡ã€èŒä¸šè½¨è¿¹è¿›è¡Œç»¼åˆæ‰“åˆ†ï¼ˆ5åˆ†åˆ¶ï¼‰ã€‚
    
    ç›®æ ‡ JSON ç»“æ„ï¼š
    {JSON_SCHEMA}
    """
    
    # é˜²æ­¢ Tokens æº¢å‡ºï¼Œæˆªå–å‰ 12000 å­—ç¬¦ (V3 æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡ï¼Œè¿™é‡Œé€‚å½“æ”¾å®½)
    truncated_text = text[:12000]

    payload = {
        "model": "deepseek-ai/DeepSeek-V3.2", # ç”¨æˆ·æŒ‡å®šçš„æ–°æ¨¡å‹
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹ç®€å†å†…å®¹ï¼š\n\n{truncated_text}"}
        ],
        "temperature": 0.1, 
        "response_format": {"type": "json_object"}
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        result = response.json()
        content = result['choices'][0]['message']['content']
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ markdown ç¬¦å·
        content = content.replace("```json", "").replace("```", "").strip()
        return json.loads(content)
    except Exception as e:
        st.error(f"API è°ƒç”¨å¤±è´¥: {str(e)}")
        return None

# ==========================================
# 3. é˜¶æ®µä¸‰ï¼šPython è§„åˆ™è¯„åˆ†å¼•æ“ (Rule Engine)
# ==========================================

def calculate_score(data):
    """
    ä¸¥æ ¼æŒ‰ç…§ Excel æ–‡æ¡£ä¸­çš„æ‰“åˆ†è¡¨è¿›è¡Œè¯„åˆ†
    ç°åœ¨åˆ©ç”¨ AI è¯†åˆ«å‡ºçš„ Tag è¿›è¡Œæ‰“åˆ†ï¼Œä¸å†ç¡¬ç¼–ç å­¦æ ¡åå•
    """
    score = 0
    logs = [] # è®°å½•åŠ åˆ†åŸå› 

    basic = data.get('basic_info', {})
    edu = data.get('education', {})
    work = data.get('work_experience', {})
    achieve = data.get('achievements', {})
    ai = data.get('ai_assessment', {})

    # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è·å–æ•°å­—
    def get_num(val):
        try:
            return float(val)
        except (ValueError, TypeError):
            return 0.0

    # --- 1. ä¸“ä¸šåŒ¹é… ---
    score_p1 = 0
    comp_str = str(achieve.get('teaching_competition', [])) + str(achieve.get('honor_titles', []))
    if "çœ" in comp_str and ("ä¸€ç­‰å¥–" in comp_str or "å‰ä¸‰" in comp_str):
        score_p1 += 5
        logs.append("ä¸“ä¸š: çœçº§å¥–é¡¹ +5")
    score += score_p1

    # --- 2. å­¦ä¹ ç»å† (å®Œå…¨ä¾èµ– AI çš„ Tier è¯†åˆ«) ---
    # é«˜ä¸­
    hs_tier = str(edu.get('high_school_tier', ''))
    if "é‡ç‚¹" in hs_tier or "å¿ä¸­" in hs_tier:
        score += 3
        logs.append(f"é«˜ä¸­: {hs_tier} +3")
    elif "æ™®é€š" not in hs_tier and "æœªçŸ¥" not in hs_tier: # AI è¯†åˆ«å‡ºäº†å…·ä½“åå­—ä½†æ²¡å½’ç±»ä¸ºé‡ç‚¹
         pass # å¯ä»¥åœ¨ Prompt ä¼˜åŒ–ï¼Œè¿™é‡Œä¿å®ˆå¤„ç†
    
    # æœ¬ç§‘ (AI æ ‡ç­¾: C9, 985, 211, æµ·å¤–åæ ¡)
    b_tier = str(edu.get('bachelor_tier', ''))
    if "C9" in b_tier:
        score += 5
        logs.append("æœ¬ç§‘: C9 +5")
    elif "985" in b_tier or "æµ·å¤–åæ ¡" in b_tier:
        score += 3
        logs.append(f"æœ¬ç§‘: {b_tier} +3")
    elif "211" in b_tier or "é‡ç‚¹å¸ˆèŒƒ" in b_tier:
        score += 1
        logs.append(f"æœ¬ç§‘: {b_tier} +1")
    
    # ç ”ç©¶ç”Ÿ
    m_tier = str(edu.get('master_tier', ''))
    if "C9" in m_tier:
        score += 5
        logs.append("ç¡•å£«: C9 +5")
    elif "985" in m_tier or "æµ·å¤–åæ ¡" in m_tier:
        score += 3
        logs.append(f"ç¡•å£«: {m_tier} +3")
    elif "211" in m_tier or "é‡ç‚¹å¸ˆèŒƒ" in m_tier:
        score += 1
        logs.append(f"ç¡•å£«: {m_tier} +1")

    # ç•™å­¦
    abroad = get_num(edu.get('study_abroad_years'))
    if abroad >= 2:
        score += 2
        logs.append("ç•™å­¦: 2å¹´ä»¥ä¸Š +2")
    
    exchange = str(edu.get('exchange_experience', 'å¦'))
    if exchange == 'æ˜¯':
        score += 1
        logs.append("ç•™å­¦: äº¤æ¢ç»å† +1")

    # --- 3. å®¶åº­èƒŒæ™¯ ---
    gender = str(basic.get('gender', ''))
    marital = str(basic.get('marital_status', ''))
    if gender == 'ç”·':
        score += 3
        logs.append("èƒŒæ™¯: ç”·æ€§ +3")
    if gender == 'å¥³' and 'å·²è‚²' in marital:
        score += 1
        logs.append("èƒŒæ™¯: å·²å©šå·²è‚² +1")
    
    parents = str(basic.get('parents_background', ''))
    if any(k in parents for k in ['æ•™å¸ˆ', 'å­¦æ ¡', 'æœºå…³', 'ç ”å‘', 'å…¬åŠ¡å‘˜']):
        score += 1
        logs.append("èƒŒæ™¯: çˆ¶æ¯ä¹¦é¦™/æœºå…³ +1")
        
    residence = str(basic.get('residence', ''))
    if TARGET_CITY in residence:
        score += 1
        logs.append(f"èƒŒæ™¯: ä½{TARGET_CITY} +1")
        
    partner = str(basic.get('partner_location', ''))
    if TARGET_CITY in partner:
        score += 1
        logs.append(f"èƒŒæ™¯: é…å¶åœ¨{TARGET_CITY} +1")

    # --- 4. å·¥ä½œç»å† ---
    # åˆ©ç”¨ AI è¯†åˆ«çš„å­¦æ ¡æ¡£æ¬¡
    work_tier = str(work.get('school_tier', ''))
    if "é‡ç‚¹" in work_tier or "çŸ¥å" in work_tier:
        score += 3
        logs.append(f"å·¥ä½œ: {work_tier} +3")
        
    non_teaching = get_num(work.get('non_teaching_gap'))
    if non_teaching > 2:
        score -= 3
        logs.append("å·¥ä½œ: éæ•™ç©ºçª—æœŸ -3")
        
    overseas_work = get_num(work.get('overseas_work_years'))
    if overseas_work >= 1:
        score += 3
        logs.append("å·¥ä½œ: æµ·å¤–å·¥ä½œ +3")

    # --- 5. æ•™å­¦ç§‘ç ” ---
    titles = str(achieve.get('honor_titles', []))
    if any(k in titles for k in ['ç‰¹çº§', 'å­¦ç§‘å¸¦å¤´äºº', 'éª¨å¹²', 'ä¼˜é’']):
        score += 5
        logs.append("èƒ½åŠ›: æ ¸å¿ƒå¤´è¡” +5")
    
    contest = str(achieve.get('teaching_competition', []))
    if "ä¸€ç­‰å¥–" in contest and ("åŒº" in contest or "å¸‚" in contest or "çœ" in contest):
        score += 3
        logs.append("èƒ½åŠ›: èµ›è¯¾ä¸€ç­‰å¥– +3")
        
    academic = str(achieve.get('academic_results', []))
    if "è¯¾é¢˜" in academic or "è®ºæ–‡" in academic:
        score += 1 
        logs.append("èƒ½åŠ›: å­¦æœ¯æˆæœ +1")

    # --- 6. ç®¡ç†èƒ½åŠ› ---
    mgmt = str(work.get('management_role', ''))
    if mgmt and mgmt not in ['æ— ', 'æœªæåŠ', 'None', 'null']:
        if "å¹´çº§ç»„é•¿" in mgmt or "æ•™ç ”" in mgmt or "ä¸­å±‚" in mgmt:
            score += 3
            logs.append("ç®¡ç†: ä¸­å±‚/ç»„é•¿ +3")
    
    ht_years = get_num(work.get('head_teacher_years'))
    if ht_years >= 5:
        score += 3
        logs.append("ç®¡ç†: ç­ä¸»ä»»5å¹´+ +3")
    elif ht_years > 0:
        score += 1
        logs.append("ç®¡ç†: æœ‰ç­ä¸»ä»»ç»å† +1")

    # --- 7 & 8. ä¸ªäººç‰¹è´¨ä¸AIæ½œè´¨ ---
    potential = get_num(ai.get('potential_score'))
    if potential > 0:
        score += potential
        logs.append(f"AIæ½œè´¨: +{potential}")

    return score, "; ".join(logs)

# ==========================================
# 4. ä¸»ç¨‹åºç•Œé¢ (UI)
# ==========================================

def main():
    st.title("ğŸ“ æ™ºèƒ½ç®€å†ç­›é€‰ç³»ç»Ÿ V3.2")
    st.markdown("""
    **æ ¸å¿ƒå‡çº§ï¼š**
    * **å¼•æ“**: é›†æˆ `deepseek-ai/DeepSeek-V3.2`
    * **æ™ºèƒ½è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ« C9/985/211 åŠæµ·å¤–åæ ¡ï¼Œæ— éœ€ç»´æŠ¤é™¢æ ¡åå•
    """)
    
    # --- ä¾§è¾¹æ é…ç½® ---
    st.sidebar.header("é…ç½®åŒºåŸŸ")
    
    api_key = None
    try:
        api_key = st.secrets["SILICONFLOW_API_KEY"]
        st.sidebar.success("âœ… API Key å·²ä» Secrets åŠ è½½")
    except Exception:
        pass
        
    if not api_key:
        api_key = st.sidebar.text_input("è¯·è¾“å…¥ SiliconFlow API Key", type="password")
        if not api_key:
            st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ API Key ä»¥ç»§ç»­")
            
    uploaded_files = st.sidebar.file_uploader(
        "æ‰¹é‡ä¸Šä¼ ç®€å† (æ”¯æŒ PDF/Word)", 
        type=['pdf', 'docx', 'doc'], 
        accept_multiple_files=True
    )

    # --- å¼€å§‹åˆ†ææŒ‰é’® ---
    if st.sidebar.button("ğŸš€ å¼€å§‹ DeepSeek åˆ†æ") and uploaded_files and api_key:
        
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_files = len(uploaded_files)
        
        # 1. è§£ææ–‡ä»¶
        status_text.text("ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶...")
        file_data_list = parse_files(uploaded_files)
        
        for i, file_data in enumerate(file_data_list):
            file_name = file_data['filename']
            status_text.text(f"ğŸ¤– DeepSeek-V3.2 æ­£åœ¨æ€è€ƒ ({i+1}/{total_files}): {file_name} ...")
            
            # 2. AI æå–
            json_result = call_deepseek_api(file_data['content'], api_key)
            
            if json_result:
                # 3. è§„åˆ™è¯„åˆ† (åŸºäº AI çš„è¯†åˆ«ç»“æœ)
                total_score, score_logs = calculate_score(json_result)
                
                # æ‰å¹³åŒ–æ•°æ®ç”¨äº DataFrame
                basic = json_result.get('basic_info', {})
                edu = json_result.get('education', {})
                work = json_result.get('work_experience', {})
                ai_eval = json_result.get('ai_assessment', {})
                achieve = json_result.get('achievements', {})
                
                # æ ¼å¼åŒ–åˆ—è¡¨ä¸ºå­—ç¬¦ä¸²
                honor_str = ", ".join(achieve.get('honor_titles', [])) if isinstance(achieve.get('honor_titles'), list) else str(achieve.get('honor_titles', ''))
                
                # ç»„åˆæ˜¾ç¤ºé™¢æ ¡å’Œå±‚æ¬¡
                bach_display = f"{edu.get('bachelor_school', '')} ({edu.get('bachelor_tier', '')})"
                mast_display = f"{edu.get('master_school', '')} ({edu.get('master_tier', '')})"
                
                row = {
                    "æºæ–‡ä»¶": file_name,
                    # åŸºç¡€ä¿¡æ¯
                    "å§“å": basic.get('name'),
                    "æ€§åˆ«": basic.get('gender'),
                    "å¹´é¾„": basic.get('age'),
                    "ç”µè¯": basic.get('phone'),
                    "å­¦å†å±‚æ¬¡": f"{edu.get('bachelor_tier', '')}/{edu.get('master_tier', '')}",
                    "æœ¬ç§‘é™¢æ ¡": bach_display,
                    "ç ”ç©¶ç”Ÿé™¢æ ¡": mast_display,
                    "ä¸“ä¸š": f"{edu.get('bachelor_major', '')}/{edu.get('master_major', '')}",
                    "åº”è˜å­¦ç§‘": basic.get('subject'),
                    
                    # æ ¸å¿ƒç­›é€‰ (é«˜äº®åŒº)
                    "é¢„ä¼°è¯„åˆ†": total_score,
                    "è¯„åˆ†æ˜ç»†": score_logs,
                    "æ•™é¾„": work.get('teaching_years'),
                    "èŒç§°/å¤´è¡”": honor_str,
                    "ç°å•ä½": f"{work.get('current_company')} ({work.get('school_tier', '')})",
                    
                    # AI è¾…åŠ©åŒº
                    "äº®ç‚¹æ‘˜è¦": ai_eval.get('summary'),
                    "é£é™©æç¤º": ai_eval.get('risk_warning'),
                    "AIæ½œè´¨åˆ†": ai_eval.get('potential_score'),
                    "èŒä¸šè½¨è¿¹": ai_eval.get('career_trajectory')
                }
                results.append(row)
            else:
                st.error(f"âŒ æ–‡ä»¶ {file_name} è§£æå¤±è´¥æˆ– API æ— å“åº”")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((i + 1) / total_files)
            time.sleep(0.5) 

        status_text.success("âœ… åˆ†æå®Œæˆï¼")
        
        # 4. ç”ŸæˆæŠ¥è¡¨
        if results:
            df = pd.read_json(json.dumps(results))
            
            if "é¢„ä¼°è¯„åˆ†" in df.columns:
                df = df.sort_values(by="é¢„ä¼°è¯„åˆ†", ascending=False)
            
            st.subheader("ğŸ“Š ç®€å†åˆ†æç»“æœé¢„è§ˆ")
            st.dataframe(df.style.background_gradient(subset=['é¢„ä¼°è¯„åˆ†'], cmap='Greens'))
            
            # å¯¼å‡º Excel
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                df.to_excel(writer, sheet_name='é¢è¯•èŠ±åå†Œ', index=False)
                
                workbook = writer.book
                worksheet = writer.sheets['é¢è¯•èŠ±åå†Œ']
                
                # è®¾ç½®åˆ—å®½
                worksheet.set_column('A:H', 15)
                worksheet.set_column('I:I', 10) # è¯„åˆ†
                worksheet.set_column('J:M', 30) # æ˜ç»†åŠ å®½
                worksheet.set_column('N:Q', 30)
                
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½é¢è¯•èŠ±åå†Œ Excel",
                data=buffer.getvalue(),
                file_name=f"é¢è¯•èŠ±åå†Œ_V3.2_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.ms-excel"
            )
        else:
            st.warning("æœªèƒ½æå–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ç®€å†æ ¼å¼æˆ– API è¿æ¥ã€‚")

if __name__ == "__main__":
    main()




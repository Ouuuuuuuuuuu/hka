import streamlit as st
import pandas as pd
import requests
import time
import random
import datetime
from bs4 import BeautifulSoup
import os
from urllib.parse import urlparse, parse_qs
import shutil
import subprocess
import sys

# --- æ–°å¢ï¼šPlaywright åº“ ---
from playwright.sync_api import sync_playwright

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="WeChat Insight Pro",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æ ¸å¿ƒçˆ¬è™«é€»è¾‘ (è´Ÿè´£æŠ“å–æ•°æ®) ---
class WechatCrawler:
    def __init__(self, token, cookie):
        self.base_url = "https://mp.weixin.qq.com/cgi-bin/appmsg"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Cookie": cookie
        }
        self.token = token
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def search_account(self, query):
        """æœç´¢å…¬ä¼—å·è·å–fakeid"""
        search_url = "https://mp.weixin.qq.com/cgi-bin/searchbiz"
        params = {
            "action": "search_biz", "token": self.token, "lang": "zh_CN",
            "f": "json", "ajax": "1", "query": query, "begin": "0", "count": "5",
        }
        try:
            res = self.session.get(search_url, params=params)
            data = res.json()
            # æ£€æŸ¥æ˜¯å¦æœ‰æƒé™é”™è¯¯
            if "base_resp" in data and data["base_resp"]["ret"] != 0:
                st.error(f"å¾®ä¿¡æ¥å£æŠ¥é”™: {data['base_resp']}")
                return []
            return data.get("list", [])
        except Exception as e:
            st.error(f"æœç´¢è¯·æ±‚å¼‚å¸¸: {e}")
            return []

    def fetch_article_list(self, fakeid, pages=3):
        """è·å–æ–‡ç« åˆ—è¡¨å…ƒæ•°æ®"""
        all_articles = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        for page in range(pages):
            status_text.text(f"ğŸ“¡ æ­£åœ¨æ‰«æåˆ—è¡¨ç¬¬ {page + 1}/{pages} é¡µ...")
            params = {
                "token": self.token, "lang": "zh_CN", "f": "json", "ajax": "1",
                "action": "list_ex", "fakeid": fakeid, "query": "",
                "begin": str(page * 5), "count": "5", "type": "9",
            }
            try:
                res = self.session.get(self.base_url, params=params)
                data = res.json()
                if "app_msg_list" in data:
                    for item in data["app_msg_list"]:
                        all_articles.append({
                            "aid": item.get("aid"),
                            "title": item.get("title"),
                            "digest": item.get("digest"),
                            "link": item.get("link"),
                            "create_time": item.get("create_time"),
                            "cover": item.get("cover"),
                            "item_idx": item.get("item_idx", 1),
                            "copyright_type": item.get("copyright_type", 0)
                        })
                else:
                    break
                progress_bar.progress((page + 1) / pages)
                time.sleep(random.uniform(1.0, 2.0))
            except:
                break
        
        progress_bar.empty()
        status_text.empty()
        return all_articles

    def fetch_article_content(self, url):
        """æ·±åº¦é‡‡é›†ï¼šè®¿é—®è¯¦æƒ…é¡µè·å–æ­£æ–‡"""
        try:
            res = self.session.get(url, timeout=10)
            soup = BeautifulSoup(res.text, "lxml")
            
            content_div = soup.find("div", {"id": "js_content"})
            if content_div:
                for p in content_div.find_all('p'):
                    p.insert_after('\n')
                content_text = content_div.get_text().strip()
            else:
                content_text = ""
            
            author_tag = soup.find("strong", {"class": "profile_nickname"})
            if not author_tag:
                author_tag = soup.find("a", {"id": "js_name"})
            author = author_tag.get_text().strip() if author_tag else "æœªçŸ¥"
            
            return content_text, author, "IPæœªçŸ¥"
        except Exception:
            return "", "è·å–å¤±è´¥", "è·å–å¤±è´¥"

# --- æ•°æ®å¤„ç†å·¥å…· ---
def process_data(articles, crawler=None, fetch_details=False):
    if not articles:
        return pd.DataFrame()
    df = pd.DataFrame(articles)
    df['publish_time'] = pd.to_datetime(df['create_time'], unit='s')
    df['date'] = df['publish_time'].dt.date
    df['is_original'] = df['copyright_type'].apply(lambda x: 'åŸåˆ›' if x == 1 else 'è½¬è½½')
    
    if fetch_details and crawler:
        st.info("ğŸ¢ æ­£åœ¨æ·±åº¦é‡‡é›†å…¨æ–‡...")
        details = []
        bar = st.progress(0)
        for idx, row in df.iterrows():
            content, author, ip = crawler.fetch_article_content(row['link'])
            details.append({'content': content, 'author': author, 'ip_location': ip})
            bar.progress((idx + 1) / len(df))
            time.sleep(0.5)
        detail_df = pd.DataFrame(details)
        df = pd.concat([df, detail_df], axis=1)
        bar.empty()
    else:
        df['content'] = ""
        df['author'] = "æœªé‡‡é›†"
    return df

# --- è¾…åŠ©å‡½æ•°ï¼šå¼ºåŠ›å®‰è£…æµè§ˆå™¨å†…æ ¸åŠä¾èµ– ---
def force_install_playwright(install_deps=False):
    """
    é’ˆå¯¹ Streamlit ç¯å¢ƒçš„å¼ºåˆ¶å®‰è£…è„šæœ¬
    install_deps=True æ—¶ä¼šå°è¯•å®‰è£…ç³»ç»Ÿçº§ä¾èµ– (éœ€è¦ sudo æƒé™)
    """
    try:
        # ä½¿ç”¨å½“å‰è¿è¡Œ Streamlit çš„ Python è§£é‡Šå™¨å»å®‰è£…ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´
        if install_deps:
            # å®‰è£…ç³»ç»Ÿä¾èµ– (å¯¹åº” sudo playwright install-deps)
            cmd = [sys.executable, "-m", "playwright", "install-deps"]
        else:
            # å®‰è£…æµè§ˆå™¨å†…æ ¸ (å¯¹åº” playwright install chromium)
            cmd = [sys.executable, "-m", "playwright", "install", "chromium"]
            
        process = subprocess.run(cmd, capture_output=True, text=True)
        
        if process.returncode != 0:
            return False, process.stderr
        return True, "å®‰è£…æˆåŠŸ"
    except Exception as e:
        return False, str(e)

# --- æ ¸å¿ƒï¼šPlaywright è‡ªåŠ¨ç™»å½•é€»è¾‘ ---
def auto_login_playwright():
    """
    ä½¿ç”¨ Playwright å¯åŠ¨æµè§ˆå™¨å¹¶ç›‘å¬ç™»å½•çŠ¶æ€
    åŒ…å«è‡ªåŠ¨å®‰è£…å†…æ ¸çš„å®¹é”™é€»è¾‘
    """
    status_placeholder = st.empty()
    token = None
    cookie_string = None
    
    status_placeholder.info("ğŸš€ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨å¼•æ“...")
    
    try:
        with sync_playwright() as p:
            # 1. å°è¯•å¯åŠ¨æµè§ˆå™¨
            try:
                browser = p.chromium.launch(headless=False)
            except Exception as e:
                # æ•è·æµè§ˆå™¨é”™è¯¯ï¼Œè¿›è¡Œè‡ªåŠ¨ä¿®å¤
                error_msg = str(e)
                
                # æƒ…å†µ A: ç¼ºå°‘æµè§ˆå™¨å†…æ ¸ (Executable doesn't exist)
                if "Executable doesn't exist" in error_msg:
                    status_placeholder.warning("âš™ï¸ æ£€æµ‹åˆ°æµè§ˆå™¨å†…æ ¸ç¼ºå¤±ï¼Œæ­£åœ¨è‡ªåŠ¨ä¸‹è½½ (çº¦éœ€ 1-2 åˆ†é’Ÿ)...")
                    success, msg = force_install_playwright(install_deps=False)
                    if success:
                        status_placeholder.success("âœ… å†…æ ¸å®‰è£…å®Œæˆï¼æ­£åœ¨å¯åŠ¨...")
                        browser = p.chromium.launch(headless=False)
                    else:
                        status_placeholder.error(f"âŒ è‡ªåŠ¨å®‰è£…å¤±è´¥: {msg}")
                        return None, None
                        
                # æƒ…å†µ B: ç¼ºå°‘ç³»ç»Ÿä¾èµ– (Host system is missing dependencies)
                elif "Host system is missing dependencies" in error_msg:
                    status_placeholder.warning("âš™ï¸ æ£€æµ‹åˆ°ç³»ç»Ÿç»„ä»¶ç¼ºå¤±ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨ä¿®å¤...")
                    
                    # å°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ–
                    success, msg = force_install_playwright(install_deps=True)
                    
                    if success:
                        status_placeholder.success("âœ… ç³»ç»Ÿç»„ä»¶ä¿®å¤å®Œæˆï¼æ­£åœ¨å¯åŠ¨...")
                        browser = p.chromium.launch(headless=False)
                    else:
                        # è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼ˆé€šå¸¸å› ä¸ºéœ€è¦è¾“å…¥å¯†ç ï¼‰ï¼Œç»™ç”¨æˆ·æä¾›æœ€ç®€å•çš„å¤åˆ¶å‘½ä»¤
                        status_placeholder.error("âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥ï¼ˆæƒé™ä¸è¶³ï¼‰ã€‚è¯·å¤åˆ¶ä¸‹æ–¹å‘½ä»¤åˆ°ç»ˆç«¯è¿è¡Œï¼š")
                        st.code("sudo playwright install-deps", language="bash")
                        st.caption("æç¤ºï¼šåœ¨ç»ˆç«¯ç²˜è´´å¹¶å›è½¦åï¼Œè¾“å…¥æ‚¨çš„å¼€æœºå¯†ç å³å¯ï¼ˆè¾“å…¥æ—¶å¯†ç ä¸æ˜¾ç¤ºï¼‰ã€‚")
                        return None, None
                else:
                    raise e

            context = browser.new_context()
            page = context.new_page()

            status_placeholder.info("ğŸ”— æ­£åœ¨æ‰“å¼€å¾®ä¿¡ç™»å½•é¡µ...")
            page.goto("https://mp.weixin.qq.com/")
            
            status_placeholder.warning("ğŸ“± è¯·æ‹¿èµ·æ‰‹æœºå¾®ä¿¡æ‰«ç ç™»å½• (è¯·å‹¿å…³é—­æµè§ˆå™¨)...")

            # 2. å¾ªç¯æ£€æµ‹ URL Token
            max_retries = 120  # ç­‰å¾… 120 ç§’
            for i in range(max_retries):
                # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦è¢«æ‰‹åŠ¨å…³é—­
                if not page.context.pages: # ç®€å•çš„æ£€æŸ¥æ–¹å¼
                    status_placeholder.error("æµè§ˆå™¨å·²å…³é—­ï¼Œæ“ä½œå–æ¶ˆã€‚")
                    return None, None
                
                try:
                    if page.is_closed():
                         status_placeholder.error("æµè§ˆå™¨å·²å…³é—­ï¼Œæ“ä½œå–æ¶ˆã€‚")
                         return None, None
                    current_url = page.url
                except:
                    status_placeholder.error("æµè§ˆå™¨è¿æ¥æ–­å¼€ã€‚")
                    return None, None

                if "token=" in current_url:
                    status_placeholder.success(f"âœ… ç™»å½•æˆåŠŸï¼æ­£åœ¨æå–å‡­è¯... ({i}s)")
                    
                    # A. æå– Token
                    parsed_url = urlparse(current_url)
                    params = parse_qs(parsed_url.query)
                    token = params.get("token", [""])[0]
                    
                    # B. æå– Cookies
                    cookies_list = context.cookies()
                    cookie_string = "; ".join([f"{cookie['name']}={cookie['value']}" for cookie in cookies_list])
                    
                    # ç¨ç­‰ç‰‡åˆ»ç¡®ä¿æ•°æ®ç¨³å®š
                    time.sleep(1)
                    break
                else:
                    time.sleep(1)
            
            if not token:
                status_placeholder.error("â° ç™»å½•è¶…æ—¶ï¼Œè¯·é‡è¯•ã€‚")
            
            browser.close()
            
    except Exception as e:
        status_placeholder.error(f"å¯åŠ¨å¤±è´¥: {str(e)}")
        return None, None
        
    return token, cookie_string

import streamlit as st
import pandas as pd
import requests
import time
import random
import plotly.express as px
import datetime
from bs4 import BeautifulSoup
from collections import Counter
import jieba.analyse
import platform
import os
import shutil
import glob

# --- æ–°å¢ï¼šè‡ªåŠ¨åŒ–ç™»å½•æ¨¡å— (å¤šæµè§ˆå™¨æ”¯æŒ) ---
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.edge.service import Service as EdgeService
from selenium.webdriver.firefox.service import Service as FirefoxService

# å¼•å…¥ webdriver_manager
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from webdriver_manager.firefox import GeckoDriverManager

# ==========================================
# ğŸš€ æ ¸å¿ƒé»‘ç§‘æŠ€ï¼šé…ç½®å›½å†…é•œåƒæº (è§£å†³ç½‘ç»œæŠ¥é”™)
# ==========================================
# å¼ºåˆ¶è®© Chrome é©±åŠ¨ä»æ·˜å®é•œåƒä¸‹è½½ï¼Œè§£å†³ "Could not reach host" é—®é¢˜
os.environ['WDM_BASE_URL'] = "https://npmmirror.com/mirrors/chromedriver"
os.environ['WDM_SSL_VERIFY'] = '0' 

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="WeChat Insight Pro",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- æ™ºèƒ½é©±åŠ¨æŸ¥æ‰¾å™¨ (ä¸“é—¨è§£å†³å°ç™½æ‰¾ä¸åˆ°è·¯å¾„çš„é—®é¢˜) ---
def find_driver_automatically(browser_name):
    """
    å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨å»ç”µè„‘çš„ Downloads æ–‡ä»¶å¤¹
    æˆ–è€…ç³»ç»Ÿè·¯å¾„é‡Œâ€œæ¡â€ä¸€ä¸ªé©±åŠ¨å›æ¥ç”¨ã€‚
    """
    system_name = platform.system()
    driver_filename = ""
    
    if browser_name == "Chrome":
        driver_filename = "chromedriver"
    elif browser_name == "Edge":
        driver_filename = "msedgedriver"
    
    if system_name == "Windows":
        driver_filename += ".exe"

    # 1. æœç´¢å½“å‰ç›®å½•
    if os.path.exists(driver_filename):
        return os.path.abspath(driver_filename)
    
    # 2. æœç´¢ç”¨æˆ·çš„ Downloads æ–‡ä»¶å¤¹ (è¿™æ˜¯å°ç™½æœ€å®¹æ˜“å­˜æ”¾çš„åœ°æ–¹)
    home = os.path.expanduser("~")
    downloads_path = os.path.join(home, "Downloads")
    
    # åœ¨ Downloads é‡Œæ‰¾ (åŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼Œé˜²æ­¢è§£å‹åœ¨é‡Œé¢)
    # ç®€å•æœç´¢ Downloads æ ¹ç›®å½•
    target = os.path.join(downloads_path, driver_filename)
    if os.path.exists(target):
        return target
        
    # 3. å°è¯•ä» PATH ç¯å¢ƒå˜é‡é‡Œæ‰¾
    return shutil.which(driver_filename)

# --- æ ¸å¿ƒçˆ¬è™«é€»è¾‘ (ä¿æŒä¸å˜) ---
class WechatCrawler:
    def __init__(self, token, cookie):
        self.base_url = "https://mp.weixin.qq.com/cgi-bin/appmsg"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36",
            "Cookie": cookie
        }
        self.token = token
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def search_account(self, query):
        search_url = "https://mp.weixin.qq.com/cgi-bin/searchbiz"
        params = {
            "action": "search_biz", "token": self.token, "lang": "zh_CN",
            "f": "json", "ajax": "1", "query": query, "begin": "0", "count": "5",
        }
        try:
            res = self.session.get(search_url, params=params)
            data = res.json()
            return data.get("list", [])
        except Exception as e:
            st.error(f"æœç´¢è¯·æ±‚å¼‚å¸¸: {e}")
            return []

    def fetch_article_list(self, fakeid, pages=3):
        all_articles = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        for page in range(pages):
            status_text.text(f"ğŸ“¡ æ­£åœ¨æ‰«æåˆ—è¡¨ç¬¬ {page + 1}/{pages} é¡µ...")
            params = {
                "token": self.token, "lang": "zh_CN", "f": "json", "ajax": "1",
                "action": "list_ex", "fakeid": fakeid, "query": "",
                "begin": str(page * 5), "count": "5", "type": "9",
            }
            try:
                res = self.session.get(self.base_url, params=params)
                data = res.json()
                if "app_msg_list" in data:
                    for item in data["app_msg_list"]:
                        all_articles.append({
                            "aid": item.get("aid"),
                            "title": item.get("title"),
                            "digest": item.get("digest"),
                            "link": item.get("link"),
                            "create_time": item.get("create_time"),
                            "cover": item.get("cover"),
                            "item_idx": item.get("item_idx", 1),
                            "copyright_type": item.get("copyright_type", 0)
                        })
                else:
                    break
                progress_bar.progress((page + 1) / pages)
                time.sleep(random.uniform(1.0, 2.0))
            except:
                break
        
        progress_bar.empty()
        status_text.empty()
        return all_articles

    def fetch_article_content(self, url):
        try:
            res = self.session.get(url, timeout=10)
            soup = BeautifulSoup(res.text, "lxml")
            
            content_div = soup.find("div", {"id": "js_content"})
            if content_div:
                for p in content_div.find_all('p'):
                    p.insert_after('\n')
                content_text = content_div.get_text().strip()
            else:
                content_text = ""
            
            author_tag = soup.find("strong", {"class": "profile_nickname"})
            if not author_tag:
                author_tag = soup.find("a", {"id": "js_name"})
            author = author_tag.get_text().strip() if author_tag else "æœªçŸ¥"
            
            scripts = soup.find_all("script")
            ip_location = "IPæœªçŸ¥"
            for script in scripts:
                if script.string and "ip_wording" in script.string:
                    import re
                    match = re.search(r'ip_wording\s*=\s*\{\s*type\s*:\s*2\s*,\s*name\s*:\s*"(.*?)"', script.string)
                    if match:
                        ip_location = match.group(1)
                        break
            
            return content_text, author, ip_location
        except Exception:
            return "", "è·å–å¤±è´¥", "è·å–å¤±è´¥"

# --- æ•°æ®å¤„ç†å·¥å…· ---
def process_data(articles, crawler=None, fetch_details=False):
    if not articles:
        return pd.DataFrame()
    
    df = pd.DataFrame(articles)
    df['publish_time'] = pd.to_datetime(df['create_time'], unit='s')
    df['date'] = df['publish_time'].dt.date
    df['is_original'] = df['copyright_type'].apply(lambda x: 'åŸåˆ›' if x == 1 else 'è½¬è½½')
    
    if fetch_details and crawler:
        st.info("ğŸ¢ æ­£åœ¨æ·±åº¦é‡‡é›†å…¨æ–‡ï¼Œé€Ÿåº¦è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        details = []
        bar = st.progress(0)
        for idx, row in df.iterrows():
            content, author, ip = crawler.fetch_article_content(row['link'])
            details.append({'content': content, 'author': author, 'ip_location': ip})
            bar.progress((idx + 1) / len(df))
            time.sleep(0.5)
        
        detail_df = pd.DataFrame(details)
        df = pd.concat([df, detail_df], axis=1)
        bar.empty()
    else:
        df['content'] = ""
        df['author'] = "æœªé‡‡é›†"
        df['ip_location'] = "-"

    return df

# --- è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½è‡ªåŠ¨ç™»å½• ---
def auto_login_get_cookie(browser_type="Chrome"):
    driver = None
    status_placeholder = st.empty()
    
    try:
        status_placeholder.info(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {browser_type} æµè§ˆå™¨...")
        
        # 1. å°è¯•åˆå§‹åŒ–æµè§ˆå™¨
        if browser_type == "Chrome":
            options = webdriver.ChromeOptions()
            try:
                # å°è¯• A: ä½¿ç”¨å›½å†…é•œåƒè‡ªåŠ¨ä¸‹è½½
                service = ChromeService(ChromeDriverManager().install())
                driver = webdriver.Chrome(service=service, options=options)
            except Exception as e_net:
                # å°è¯• B: è‡ªåŠ¨æŸ¥æ‰¾æœ¬åœ°æ˜¯å¦å­˜åœ¨é©±åŠ¨ (Downloadsæ–‡ä»¶å¤¹ç­‰)
                local_path = find_driver_automatically("Chrome")
                if local_path:
                    st.toast(f"âœ… åœ¨æœ¬åœ°å‘ç°äº†é©±åŠ¨ï¼š{local_path}", icon="ğŸ“‚")
                    service = ChromeService(executable_path=local_path)
                    driver = webdriver.Chrome(service=service, options=options)
                else:
                    raise e_net
            
        elif browser_type == "Edge":
            options = webdriver.EdgeOptions()
            try:
                # å°è¯• A: è‡ªåŠ¨ä¸‹è½½ (å¯èƒ½è¢«å¢™)
                service = EdgeService(EdgeChromiumDriverManager().install())
                driver = webdriver.Edge(service=service, options=options)
            except Exception as e_net:
                # å°è¯• B: è‡ªåŠ¨æŸ¥æ‰¾æœ¬åœ°
                local_path = find_driver_automatically("Edge")
                if local_path:
                    st.toast(f"âœ… åœ¨æœ¬åœ°å‘ç°äº†é©±åŠ¨ï¼š{local_path}", icon="ğŸ“‚")
                    service = EdgeService(executable_path=local_path)
                    driver = webdriver.Edge(service=service, options=options)
                else:
                    # å°è¯• C: ä¸æŒ‡å®šServiceï¼Œè®©Selenium 4.xè‡ªå·±å°è¯•å¯»æ‰¾
                    try:
                        driver = webdriver.Edge(options=options)
                    except:
                        raise e_net
            
        elif browser_type == "Safari":
            # Safari æ˜¯ Mac åŸç”Ÿï¼Œæœ€ç¨³å®šï¼Œæ— é¡»ä¸‹è½½
            if platform.system() != 'Darwin':
                st.error("Safari ä»…æ”¯æŒ Mac ç³»ç»Ÿ")
                return None, None
            try:
                options = webdriver.SafariOptions()
                driver = webdriver.Safari(options=options)
            except Exception as e:
                st.error("å¯åŠ¨ Safari å¤±è´¥ã€‚è¯·æ£€æŸ¥ï¼šå±å¹•å·¦ä¸Šè§’ Safari -> åå¥½è®¾ç½® -> é«˜çº§ -> å‹¾é€‰'åœ¨èœå•æ ä¸­æ˜¾ç¤ºå¼€å‘èœå•' -> èœå•æ 'å¼€å‘' -> å‹¾é€‰'å…è®¸è¿œç¨‹è‡ªåŠ¨åŒ–'ã€‚")
                return None, None
            
        # 2. æ‰“å¼€å¾®ä¿¡
        driver.get("https://mp.weixin.qq.com/")
        status_placeholder.success("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼è¯·åœ¨å¼¹å‡ºçš„çª—å£ä¸­æ‰«ç ...")
        
        # 3. å¾ªç¯æ£€æµ‹ç™»å½•
        max_wait = 180
        start_time
